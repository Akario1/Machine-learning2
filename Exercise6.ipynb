{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b214884",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install tensorflow-datasets\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdc4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,AlphaDropout,Conv2D,Dropout,MaxPool2D\n",
    "import tensorflow.keras.optimizers \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## load the data\n",
    "(train, test) = tfds.load(\n",
    "    'svhn_cropped',\n",
    "    split=['train','test'],\n",
    "    shuffle_files = True,\n",
    "    as_supervised = True,\n",
    ")\n",
    "\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bedc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.take(2000)\n",
    "test = test.take(500)\n",
    "\n",
    "## normalize data [0,1]\n",
    "def normalize_img(img,label):\n",
    "    normalized_img = tf.cast(img, tf.float32) / 255\n",
    "    return normalized_img, label\n",
    "\n",
    "train_normalized = train.map(normalize_img)\n",
    "test_normalized = test.map(normalize_img)\n",
    "\n",
    "train_normalized = train_normalized.shuffle(2000).batch(32)\n",
    "test_normalized = test_normalized.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## buid the network\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(rate=0.25),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40f3175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1865 - loss: 2.2581 - val_accuracy: 0.1840 - val_loss: 2.2563\n",
      "Epoch 2/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1955 - loss: 2.2465 - val_accuracy: 0.1840 - val_loss: 2.2499\n",
      "Epoch 3/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1950 - loss: 2.2407 - val_accuracy: 0.1840 - val_loss: 2.2588\n",
      "Epoch 4/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1950 - loss: 2.2412 - val_accuracy: 0.1840 - val_loss: 2.2479\n",
      "Epoch 5/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1955 - loss: 2.2372 - val_accuracy: 0.1840 - val_loss: 2.2388\n",
      "Epoch 6/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1960 - loss: 2.2217 - val_accuracy: 0.1840 - val_loss: 2.2269\n",
      "Epoch 7/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2060 - loss: 2.1954 - val_accuracy: 0.2000 - val_loss: 2.1931\n",
      "Epoch 8/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2375 - loss: 2.1250 - val_accuracy: 0.3020 - val_loss: 2.0674\n",
      "Epoch 9/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3210 - loss: 1.9621 - val_accuracy: 0.3600 - val_loss: 1.8905\n",
      "Epoch 10/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4255 - loss: 1.7101 - val_accuracy: 0.4380 - val_loss: 1.6813\n",
      "Epoch 11/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4945 - loss: 1.4868 - val_accuracy: 0.5520 - val_loss: 1.4926\n",
      "Epoch 12/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5840 - loss: 1.2865 - val_accuracy: 0.6140 - val_loss: 1.3456\n",
      "Epoch 13/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6515 - loss: 1.0864 - val_accuracy: 0.6140 - val_loss: 1.2436\n",
      "Epoch 14/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7125 - loss: 0.9215 - val_accuracy: 0.6520 - val_loss: 1.1561\n",
      "Epoch 15/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7175 - loss: 0.8579 - val_accuracy: 0.7000 - val_loss: 1.0074\n"
     ]
    }
   ],
   "source": [
    "SGD_optimizer = tensorflow.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=SGD_optimizer,metrics=['accuracy'])\n",
    "history = model.fit(train_normalized,epochs=15, validation_data=test_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fa8b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7000 - loss: 1.0074 \n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ac522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 23:26:09.687158: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.704\n",
      "epistemic uncertainty: 0.003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_labels = []\n",
    "\n",
    "## since not split in X and Y, have to split \n",
    "for X_batch, Y_batch in test_normalized:\n",
    "    true_labels.append(Y_batch)\n",
    "    \n",
    "y_true = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "## montecarlo\n",
    "forward_passes = 20\n",
    "predictions = []\n",
    "for n in range(forward_passes):\n",
    "    forward_pass_prediction = []\n",
    "\n",
    "    for X_batch, Y_batch in test_normalized:\n",
    "        y_pred = model(X_batch, training=True)\n",
    "        forward_pass_prediction.append(y_pred.numpy())\n",
    "    \n",
    "    predictions.append(np.concatenate(forward_pass_prediction, axis=0))\n",
    "\n",
    "predictions = np.stack(predictions, axis=0)\n",
    "mean_prediction = predictions.mean(axis=0)\n",
    "y_pred_classes = np.argmax(mean_prediction, axis=1)\n",
    "mc_dropout_accuracy = np.mean(y_pred_classes == y_true)\n",
    "\n",
    "\n",
    "print(\"accuracy:\", mc_dropout_accuracy)\n",
    "epistemic_uncertainty = np.var(predictions, axis=0)\n",
    "epistemic_uncertainty = epistemic_uncertainty.mean(axis=1)\n",
    "epistemic_true_mean = epistemic_uncertainty.mean()\n",
    "print(\"epistemic uncertainty:\", round(epistemic_true_mean,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
