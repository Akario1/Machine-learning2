{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4684b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install tensorflow-datasets\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00dca00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,AlphaDropout,Conv2D,Dropout,MaxPool2D\n",
    "import tensorflow.keras.optimizers \n",
    "\n",
    "(train, test) = tfds.load(\n",
    "    'svhn_cropped',\n",
    "    split=['train','test'],\n",
    "    shuffle_files = True,\n",
    "    as_supervised = True,\n",
    ")\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ff23d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.take(2000)\n",
    "test = test.take(500)\n",
    "\n",
    "## normalize data [0,1]\n",
    "def normalize_img(img,label):\n",
    "    normalized_img = tf.cast(img, tf.float32) / 255\n",
    "    return normalized_img, label\n",
    "\n",
    "train_normalized = train.map(normalize_img)\n",
    "test_normalized = test.map(normalize_img)\n",
    "\n",
    "train_normalized = train_normalized.shuffle(2000).batch(32)\n",
    "test_normalized = test_normalized.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "187f911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daviddevoldpearson/cipher/.venv/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(rate=0.3),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b770a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m 5/63\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1320 - loss: 2.2951  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 21:35:07.056763: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:396] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.1915 - loss: 2.2575 - val_accuracy: 0.1840 - val_loss: 2.2629\n",
      "Epoch 2/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.1955 - loss: 2.2465 - val_accuracy: 0.1840 - val_loss: 2.2586\n",
      "Epoch 3/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.1955 - loss: 2.2455 - val_accuracy: 0.1840 - val_loss: 2.2535\n",
      "Epoch 4/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.1955 - loss: 2.2464 - val_accuracy: 0.1840 - val_loss: 2.2467\n",
      "Epoch 5/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2190 - loss: 2.1727 - val_accuracy: 0.2920 - val_loss: 2.0728\n",
      "Epoch 6/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3730 - loss: 1.8282 - val_accuracy: 0.4440 - val_loss: 1.6656\n",
      "Epoch 7/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5360 - loss: 1.3892 - val_accuracy: 0.5880 - val_loss: 1.3102\n",
      "Epoch 8/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6530 - loss: 1.0843 - val_accuracy: 0.6160 - val_loss: 1.2441\n",
      "Epoch 9/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7090 - loss: 0.9063 - val_accuracy: 0.6500 - val_loss: 1.1858\n",
      "Epoch 10/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7610 - loss: 0.7350 - val_accuracy: 0.6980 - val_loss: 1.1016\n",
      "Epoch 11/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7970 - loss: 0.6360 - val_accuracy: 0.6560 - val_loss: 1.2447\n",
      "Epoch 12/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8245 - loss: 0.5302 - val_accuracy: 0.7120 - val_loss: 1.2331\n",
      "Epoch 13/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8495 - loss: 0.4460 - val_accuracy: 0.7280 - val_loss: 1.1294\n",
      "Epoch 14/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8915 - loss: 0.3540 - val_accuracy: 0.7320 - val_loss: 1.3019\n",
      "Epoch 15/15\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8965 - loss: 0.3036 - val_accuracy: 0.7480 - val_loss: 1.3135\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7480 - loss: 1.3135\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=adam_optimizer,metrics=['accuracy'])\n",
    "history = model.fit(train_normalized,epochs=15, validation_data=test_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = model.evaluate(test_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
